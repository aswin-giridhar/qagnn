{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP Group Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers==3.4.0\n",
        "!pip install nltk spacy==2.1.6\n",
        "!python -m spacy download en\n",
        "\n",
        "# for torch-geometric\n",
        "!pip install torch-scatter==2.0.7 -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-sparse==0.6.9 -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-geometric==1.7.0 -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "metadata": {
        "id": "o23F0weODZou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc07263-529f-446e-d547-58fc55440177"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 763.5 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0+cu101 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0+cu101 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu101\n",
            "Collecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.62.3)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (21.3)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.9.2 transformers-3.4.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting spacy==2.1.6\n",
            "  Downloading spacy-2.1.6-cp37-cp37m-manylinux1_x86_64.whl (30.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.8 MB 92.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (2.23.0)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (2.0.6)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.6) (1.0.5)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 52.7 MB/s \n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 503 kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.6) (2021.10.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.8->spacy==2.1.6) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Installing collected packages: preshed, plac, blis, thinc, spacy\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.6\n",
            "    Uninstalling preshed-3.0.6:\n",
            "      Successfully uninstalled preshed-3.0.6\n",
            "  Attempting uninstall: plac\n",
            "    Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.6 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.6 thinc-7.0.8\n",
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074433 sha256=ef86f899cafb35c88260f9e130d63fc467a04310e7f502270ec7e7452d57edf5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sk7ptg7r/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-scatter==2.0.7\n",
            "  Downloading https://data.pyg.org/whl/torch-1.8.0%2Bcu101/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 1.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-sparse==0.6.9\n",
            "  Downloading https://data.pyg.org/whl/torch-1.8.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 663 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse==0.6.9) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse==0.6.9) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-geometric==1.7.0\n",
            "  Downloading torch_geometric-1.7.0.tar.gz (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (2.6.3)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (1.0.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (3.1.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (0.4)\n",
            "Collecting ase\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.7.0) (2.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric==1.7.0) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.7.0) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.7.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.7.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase->torch-geometric==1.7.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.0->ase->torch-geometric==1.7.0) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric==1.7.0) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==1.7.0) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.7.0) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.7.0) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.7.0) (2018.9)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 771 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.7.0) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==1.7.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==1.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.7.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.7.0) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.7.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.7.0) (3.0.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.0-py3-none-any.whl size=365400 sha256=544a79ff8618eaef72b2ac99eb056207302956724be9f93d244d5e4456922091\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/79/e4/4b036d100b9037974706a586e6eacf5e934e3bfa4a57ed02ca\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.22.1 isodate-0.6.1 rdflib-6.1.1 torch-geometric-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8vjJKxjDEOO",
        "outputId": "6b9c8950-5db1-4874-921b-7006c4ff5e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qagnn'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 85 (delta 33), reused 64 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/michiyasunaga/qagnn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd qagnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS4rcgryEpX-",
        "outputId": "599be7cc-ce35-4b14-cadf-85a452dc0216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/qagnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 ./download_raw_data.sh\n",
        "!./download_raw_data.sh\n",
        "!python preprocess.py -p <num_processes>"
      ],
      "metadata": {
        "id": "UNSNvFctEsk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 ./download_preprocessed_data.sh\n",
        "!./download_preprocessed_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jDHThGYFRkp",
        "outputId": "cbcd1628-40c8-44d9-d219-147496b633cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 16:32:53--  https://nlp.stanford.edu/projects/myasu/QAGNN/data_preprocessed_release.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4226838278 (3.9G) [application/zip]\n",
            "Saving to: ‘data_preprocessed_release.zip’\n",
            "\n",
            "data_preprocessed_r 100%[===================>]   3.94G  6.58MB/s    in 8m 12s  \n",
            "\n",
            "2022-01-25 16:41:06 (8.19 MB/s) - ‘data_preprocessed_release.zip’ saved [4226838278/4226838278]\n",
            "\n",
            "Archive:  data_preprocessed_release.zip\n",
            "   creating: data_preprocessed_release/\n",
            "   creating: data_preprocessed_release/cpnet/\n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.unpruned.graph  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.csv  \n",
            "  inflating: data_preprocessed_release/cpnet/matcher_patterns.json  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet-assertions-5.6.0.csv  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.pruned.graph  \n",
            "  inflating: data_preprocessed_release/cpnet/tzw.ent.npy  \n",
            "  inflating: data_preprocessed_release/cpnet/concept.txt  \n",
            "   creating: data_preprocessed_release/obqa/\n",
            "   creating: data_preprocessed_release/obqa/statement/\n",
            "  inflating: data_preprocessed_release/obqa/statement/train.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/dev-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/dev.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/test-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/train-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/test.statement.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/\n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/\n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/\n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/dev.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/test.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/train.tsv  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/train.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/test.tsv  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/dev.tsv  \n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/\n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/test_complete.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/train_complete.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/crowdsourced-facts.txt  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/dev_complete.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/grounded/\n",
            "  inflating: data_preprocessed_release/obqa/grounded/train.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/grounded/test.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/grounded/dev.grounded.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/graph/\n",
            "  inflating: data_preprocessed_release/obqa/graph/train.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/obqa/graph/train.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/dev.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/test.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/dev.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/obqa/graph/test.graph.adj.pk  \n",
            "   creating: data_preprocessed_release/csqa/\n",
            "   creating: data_preprocessed_release/csqa/grounded/\n",
            "  inflating: data_preprocessed_release/csqa/grounded/test.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/grounded/train.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/grounded/dev.grounded.jsonl  \n",
            "   creating: data_preprocessed_release/csqa/graph/\n",
            "  inflating: data_preprocessed_release/csqa/graph/test.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/dev.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/csqa/graph/train.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/test.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/csqa/graph/dev.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/train.graph.adj.pk.loaded_cache  \n",
            "   creating: data_preprocessed_release/csqa/statement/\n",
            "  inflating: data_preprocessed_release/csqa/statement/dev.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/statement/train.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/statement/test.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/train_rand_split.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/dev_rand_split.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/inhouse_split_qids.txt  \n",
            "  inflating: data_preprocessed_release/csqa/test_rand_split_no_answers.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 ./run_qagnn__csqa.sh\n",
        "!./run_qagnn__csqa.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L62dfxyZFhHD",
        "outputId": "efd170c9-c94a-404d-fe16-1a80ea5f6fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** hyperparameters *****\n",
            "dataset: csqa\n",
            "enc_name: roberta-large\n",
            "batch_size: 64\n",
            "learning_rate: elr 1e-5 dlr 1e-3\n",
            "gnn: dim 200 layer 5\n",
            "******************************\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55b86bac4000 @  0x7f9bf6ccc1e7 0x7f9ba259346e 0x7f9ba25e7e7c 0x7f9ba25e8aaf 0x7f9ba268a470 0x55b860cef544 0x55b860cef240 0x55b860d63627 0x55b860d5d9ee 0x55b860cf0bda 0x55b860d5f737 0x55b860d5d9ee 0x55b860cf0bda 0x55b860d62d00 0x55b860d5d9ee 0x55b860cf0bda 0x55b860d5e915 0x55b860d5dced 0x55b860cf0bda 0x55b860d5e915 0x55b860cf0afa 0x55b860d5e915 0x55b860d5d9ee 0x55b860d5d6f3 0x55b860e274c2 0x55b860e2783d 0x55b860e276e6 0x55b860dff163 0x55b860dfee0c 0x7f9bf5ab6bf7 0x55b860dfecea\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55b92ecee000 @  0x7f9bf6ccc1e7 0x7f9ba259346e 0x7f9ba25e3c7b 0x7f9ba25e3d18 0x7f9ba268b010 0x7f9ba268b73c 0x7f9ba268b85d 0x55b860cf1749 0x7f9ba25d0ef7 0x55b860cef437 0x55b860cef240 0x55b860d62973 0x55b860d5d9ee 0x55b860cf0bda 0x55b860d62d00 0x55b860d5dced 0x55b860cf0bda 0x55b860d5e915 0x55b860cf0afa 0x55b860d5e915 0x55b860d5d9ee 0x55b860d5d6f3 0x55b860e274c2 0x55b860e2783d 0x55b860e276e6 0x55b860dff163 0x55b860dfee0c 0x7f9bf5ab6bf7 0x55b860dfecea\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55b9f1f18000 @  0x7f9bf6caeb6b 0x7f9bf6cce379 0x7f9ba2e9c25e 0x7f9ba2e9d9d2 0x7f9be0740443 0x7f9bdffc8263 0x7f9be04c93f7 0x7f9be04989c0 0x7f9be02f3299 0x7f9bdffb8a7a 0x7f9be05c6e13 0x7f9be070c48b 0x7f9bf1cbbeb8 0x7f9bf1cc0500 0x7f9bf18bcb81 0x55b860cef544 0x55b860cef240 0x55b860d63627 0x55b860d5dced 0x55b860cf0bda 0x55b860d5e915 0x55b860cf0afa 0x55b860d5e915 0x55b860d5d9ee 0x55b860d5d6f3 0x55b860e274c2 0x55b860e2783d 0x55b860e276e6 0x55b860dff163 0x55b860dfee0c 0x7f9bf5ab6bf7\n",
            "100% 9741/9741 [00:12<00:00, 763.10it/s]\n",
            "100% 1221/1221 [00:01<00:00, 737.99it/s]\n",
            "100% 1140/1140 [00:01<00:00, 620.09it/s]\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55badfe3e000 @  0x7f9bf6caeb6b 0x7f9bf6cce379 0x7f9ba2e9c25e 0x7f9ba2e9d9d2 0x7f9bdfb5cad6 0x7f9bdffbeff9 0x7f9be04c939a 0x7f9be0494b19 0x7f9be044b277 0x7f9be02ef549 0x7f9bf1cbb967 0x7f9bf1cbd2e4 0x7f9bf1a66c6a 0x55b860d2f045 0x55b860cefc52 0x55b860d634d9 0x55b860d5dced 0x55b860cf1271 0x55b860d32159 0x55b860d2f0a4 0x55b860cefc52 0x55b860d634d9 0x55b860d5dced 0x55b860cf148c 0x55b860d32159 0x55b860d2f0a4 0x55b860cefd49 0x55b860d6394f 0x55b860d5dced 0x55b860cf148c 0x55b860d32159\n",
            "./run_qagnn__csqa.sh: line 38:  1081 Killed                  python3 -u qagnn.py --dataset $dataset --encoder $model -k $k --gnn_dim $gnndim -elr $elr -dlr $dlr -bs $bs -mbs $mbs --fp16 true --seed $seed --num_relation $num_relation --n_epochs $n_epochs --max_epochs_before_stop 10 --train_adj data/${dataset}/graph/train.graph.adj.pk --dev_adj data/${dataset}/graph/dev.graph.adj.pk --test_adj data/${dataset}/graph/test.graph.adj.pk --train_statements data/${dataset}/statement/train.statement.jsonl --dev_statements data/${dataset}/statement/dev.statement.jsonl --test_statements data/${dataset}/statement/test.statement.jsonl --save_model --save_dir ${save_dir_pref}/${dataset}/enc-${model}__k${k}__gnndim${gnndim}__bs${bs}__seed${seed}__${dt} $args > logs/train_${dataset}__enc-${model}__k${k}__gnndim${gnndim}__bs${bs}__seed${seed}__${dt}.log.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0,1\n",
        "\n",
        "dataset=\"csqa\"\n",
        "model='roberta-large'\n",
        "shift\n",
        "shift\n",
        "args=$@\n",
        "\n",
        "elr=\"1e-5\"\n",
        "dlr=\"1e-3\"\n",
        "bs=64\n",
        "mbs=2\n",
        "n_epochs=15\n",
        "num_relation=38 #(17 +2) * 2: originally 17, add 2 relation types (QA context -> Q node; QA context -> A node), and double because we add reverse edges\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "gnndim=200\n",
        "\n",
        "save_dir_pref='saved_models'\n",
        "mkdir -p $save_dir_pref\n",
        "mkdir -p logs\n",
        "\n",
        "for seed in 0; do\n",
        "  python3 -u qagnn.py --dataset $dataset \\\n",
        "      --encoder $model -k $k --gnn_dim $gnndim -elr $elr -dlr $dlr -bs $bs -mbs $mbs --fp16 true --seed $seed \\\n",
        "      --num_relation $num_relation \\\n",
        "      --n_epochs $n_epochs --max_epochs_before_stop 10  \\\n",
        "      --train_adj data/${dataset}/graph/train.graph.adj.pk \\\n",
        "      --dev_adj   data/${dataset}/graph/dev.graph.adj.pk \\\n",
        "      --test_adj  data/${dataset}/graph/test.graph.adj.pk \\\n",
        "      --train_statements  data/${dataset}/statement/train.statement.jsonl \\\n",
        "      --dev_statements  data/${dataset}/statement/dev.statement.jsonl \\\n",
        "      --test_statements  data/${dataset}/statement/test.statement.jsonl \\\n",
        "      --save_model \\\n",
        "      --save_dir ${save_dir_pref}/${dataset}/enc-${model}__k${k}__gnndim${gnndim}__bs${bs}__seed${seed}__${dt} $args \\\n",
        "  > logs/train_${dataset}__enc-${model}__k${k}__gnndim${gnndim}__bs${bs}__seed${seed}__${dt}.log.txt\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "acquCtSYNbRm",
        "outputId": "c2bfb9fb-24f3-415f-c5ec-1becd0353f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-102269dcbd56>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    args=$@\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 ./eval_qagnn__csqa.sh\n",
        "!./eval_qagnn__csqa.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkvRYOETF8vf",
        "outputId": "4fb254db-8bb9-494c-d6f1-c4a7aba6d578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************\n",
            "dataset: csqa\n",
            "******************************\n",
            "ecf67aaf4725\n",
            "pid: 1029\n",
            "screen: \n",
            "\n",
            "gpu: 0\n",
            "\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55b91b926000 @  0x7fb771bec1e7 0x7fb71d4b346e 0x7fb71d507e7c 0x7fb71d508aaf 0x7fb71d5aa470 0x55b90fc28544 0x55b90fc28240 0x55b90fc9c627 0x55b90fc969ee 0x55b90fc29bda 0x55b90fc98737 0x55b90fc969ee 0x55b90fc29bda 0x55b90fc9bd00 0x55b90fc969ee 0x55b90fc29bda 0x55b90fc97915 0x55b90fc29afa 0x55b90fc97915 0x55b90fc29afa 0x55b90fc97915 0x55b90fc969ee 0x55b90fc966f3 0x55b90fd604c2 0x55b90fd6083d 0x55b90fd606e6 0x55b90fd38163 0x55b90fd37e0c 0x7fb7709d6bf7 0x55b90fd37cea\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55b9deb50000 @  0x7fb771bec1e7 0x7fb71d4b346e 0x7fb71d503c7b 0x7fb71d503d18 0x7fb71d5ab010 0x7fb71d5ab73c 0x7fb71d5ab85d 0x55b90fc2a749 0x7fb71d4f0ef7 0x55b90fc28437 0x55b90fc28240 0x55b90fc9b973 0x55b90fc969ee 0x55b90fc29bda 0x55b90fc9bd00 0x55b90fc29afa 0x55b90fc97915 0x55b90fc29afa 0x55b90fc97915 0x55b90fc969ee 0x55b90fc966f3 0x55b90fd604c2 0x55b90fd6083d 0x55b90fd606e6 0x55b90fd38163 0x55b90fd37e0c 0x7fb7709d6bf7 0x55b90fd37cea\n",
            "tcmalloc: large alloc 3273826304 bytes == 0x55baa1d7a000 @  0x7fb771bceb6b 0x7fb771bee379 0x7fb71ddbc25e 0x7fb71ddbd9d2 0x7fb75b660443 0x7fb75aee8263 0x7fb75b3e93f7 0x7fb75b3b89c0 0x7fb75b213299 0x7fb75aed8a7a 0x7fb75b4e6e13 0x7fb75b62c48b 0x7fb76cbdbeb8 0x7fb76cbe0500 0x7fb76c7dcb81 0x55b90fc28544 0x55b90fc28240 0x55b90fc9c627 0x55b90fc29afa 0x55b90fc97915 0x55b90fc29afa 0x55b90fc97915 0x55b90fc969ee 0x55b90fc966f3 0x55b90fd604c2 0x55b90fd6083d 0x55b90fd606e6 0x55b90fd38163 0x55b90fd37e0c 0x7fb7709d6bf7 0x55b90fd37cea\n",
            "| num_concepts: 799273 |\n",
            "Traceback (most recent call last):\n",
            "  File \"qagnn.py\", line 432, in <module>\n",
            "    main()\n",
            "  File \"qagnn.py\", line 96, in main\n",
            "    eval_detail(args)\n",
            "  File \"qagnn.py\", line 351, in eval_detail\n",
            "    model_state_dict, old_args = torch.load(model_path, map_location=torch.device('cpu'))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 579, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'saved_models/csqa_model_hf3.4.0.pt'\n"
          ]
        }
      ]
    }
  ]
}